# signdetection

# ğŸ§  Real-Time Sign Language Action Detection

This project implements a real-time **action detection system** for **sign language recognition**, using **MediaPipe**, **OpenCV**, and a custom **LSTM-based model** trained on keypoint sequences.

It helps in bridging communication gaps for the hearing and speech impaired by identifying hand gestures and converting them into actions.
---

## ğŸ”§ Technologies Used

- ğŸ§  MediaPipe Holistic for keypoint detection (face, pose, hands)
- ğŸ¥ OpenCV for real-time video capture
- ğŸ”¢ NumPy & Pandas for data manipulation
- ğŸ¤– TensorFlow / Keras for model training
- ğŸ“ˆ Matplotlib for visualization

---

## ğŸ“‚ Project Structure
action-detection-sign/
â”‚
â”œâ”€â”€ data/                     # Raw and processed keypoint data
â”‚   â””â”€â”€ extracted_keypoints/
â”‚
â”œâ”€â”€ models/                   # Saved Keras model
â”‚   â””â”€â”€ action.h5
â”‚
â”œâ”€â”€ notebooks/                # Jupyter notebook (core development)
â”‚   â””â”€â”€ Action Detection Refined.ipynb
â”‚
â”œâ”€â”€ scripts/                  # Python scripts (optional)
â”‚   â”œâ”€â”€ detect.py             # Real-time detection script
â”‚   â”œâ”€â”€ train.py              # Model training script
â”‚
â”œâ”€â”€ demo.gif / demo.mp4       # Demo visuals
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

---

## ğŸ—ƒï¸ Dataset Info

- **Type**: Custom dataset based on body landmarks
- **Classes**: `Hello`, `Thanks`, `I Love You` (customizable)
- **Source**: Webcam input
- **Format**: Sequences of 30 frames containing keypoints
- **Keypoint Count**: 1662 per frame (Pose + Face + Left/Right hand landmarks)

---

## ğŸ—ï¸ Model Architecture

A simple LSTM model processes sequences of 30 frames (each frame contains MediaPipe keypoints):

``python
Input(shape=(30, 1662)) â†’ LSTM â†’ Dropout â†’ Dense â†’ Softmax

##How to Run

1. Install Dependencies
   pip install -r requirements.txt
2.Train the Model
   # Optional if you already have action.h5
     python scripts/train.py
3.Run Real-Time Detection
  python scripts/detect.py
 
##Future Work
	â€¢Add more sign language classes (ASL/ISL dataset)
	â€¢Export model to TF.js or TFLite for web/mobile
	â€¢Add text-to-speech output
	â€¢Create full-stack web app with Flask or Streamlit

 Connect
	â€¢Name: S Karthik
	â€¢GitHub: karthik2369
	â€¢LinkedIn: www.linkedin.com/in/skarthikml
